import argparse  
import os, sys  
import shutil  
import time  
from pathlib import Path  
  
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  
sys.path.append(BASE_DIR)  
  
print(sys.path)  
import cv2  
import torch  
import torch.backends.cudnn as cudnn  
from numpy import random  
import scipy.special  
import numpy as np  
import torchvision.transforms as transforms  
import PIL.Image as image  
  
from lib.config import cfg  
from lib.config import update_config  
from lib.utils.utils import create_logger, select_device, time_synchronized  
from lib.models import get_net  
from lib.dataset import LoadImages, LoadStreams  
from lib.core.general import non_max_suppression, scale_coords  
from lib.utils import plot_one_box  
from lib.core.function import AverageMeter  
from lib.core.postprocess import morphological_process, connect_lane  
from tqdm import tqdm  
  
normalize = transforms.Normalize(  
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]  
    )  
  
transform=transforms.Compose([  
            transforms.ToTensor(),  
            normalize,  
        ])


def test_colors():
    """æµ‹è¯•é¢œè‰²æ˜¾ç¤ºæ˜¯å¦æ­£ç¡®"""
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img = np.zeros((200, 400, 3), dtype=np.uint8)
    
    # ç»˜åˆ¶ä¸åŒé¢œè‰²çš„åŒºåŸŸ
    test_img[50:100, 50:150] = [0, 0, 255]    # çº¢è‰²åŒºåŸŸ (BGR)
    test_img[50:100, 200:300] = [0, 255, 255]  # é»„è‰²åŒºåŸŸ (BGR)  
    test_img[120:170, 50:350] = [0, 255, 0]    # ç»¿è‰²åŒºåŸŸ (BGR)
    
    # æ·»åŠ æ ‡ç­¾
    cv2.putText(test_img, 'Red (Solid)', (60, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    cv2.putText(test_img, 'Yellow (Dashed)', (210, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    cv2.putText(test_img, 'Green (Drivable)', (150, 115), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    return test_img


def analyze_lane_type(lane_mask):  
    """  
    åˆ†æè½¦é“çº¿ç±»å‹ï¼šå®çº¿æˆ–è™šçº¿  
    """  
    # ä½¿ç”¨è¿é€šç»„ä»¶åˆ†æ  
    num_labels, labels, stats, centers = cv2.connectedComponentsWithStats(  
        lane_mask.astype(np.uint8), connectivity=8, ltype=cv2.CV_32S)  
      
    solid_mask = np.zeros_like(lane_mask)  
    dashed_mask = np.zeros_like(lane_mask)  
    
    print(f"ğŸ” å‘ç° {num_labels-1} ä¸ªè½¦é“çº¿è¿é€šç»„ä»¶")
    
    # æ”¶é›†æ‰€æœ‰ç»„ä»¶çš„ç‰¹å¾ä¿¡æ¯ç”¨äºç›¸å¯¹æ¯”è¾ƒ
    components_info = []
    for i in range(1, num_labels):  
        x, y, w, h, area = stats[i]  
        if area < 50:  
            continue
        
        component_mask = (labels == i).astype(np.uint8)  
        density = np.sum(component_mask) / (w * h + 1e-6)
        aspect_ratio = max(w, h) / (min(w, h) + 1e-6)
        
        components_info.append({
            'index': i,
            'component_mask': component_mask,
            'x': x, 'y': y, 'w': w, 'h': h, 'area': area,
            'density': density,
            'aspect_ratio': aspect_ratio
        })
    
    if not components_info:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è½¦é“çº¿ç»„ä»¶")
        return solid_mask, dashed_mask
    
    # æŒ‰å¯†åº¦æ’åºï¼Œé€šå¸¸è™šçº¿å¯†åº¦æ›´ä½
    components_info.sort(key=lambda x: x['density'])
    
    # æ™ºèƒ½åˆ†ç±»ç­–ç•¥ï¼š
    # 1. å¦‚æœåªæœ‰1-2ä¸ªç»„ä»¶ï¼Œä¸”å¯†åº¦éƒ½å¾ˆä½ï¼Œè€ƒè™‘å°†æœ€ä½å¯†åº¦çš„è®¾ä¸ºè™šçº¿
    # 2. å¦‚æœæœ‰3ä¸ªæˆ–æ›´å¤šç»„ä»¶ï¼Œå°†å¯†åº¦æœ€ä½çš„1/3è®¾ä¸ºè™šçº¿
    # 3. åŒæ—¶è€ƒè™‘ä½ç½®å› ç´ ï¼ˆä¸­é—´è½¦é“çº¿æ›´å¯èƒ½æ˜¯è™šçº¿ï¼‰
    
    total_components = len(components_info)
    
    for idx, comp in enumerate(components_info):
        i = comp['index']
        component_mask = comp['component_mask']
        x, y, w, h, area = comp['x'], comp['y'], comp['w'], comp['h'], comp['area']
        density = comp['density']
        aspect_ratio = comp['aspect_ratio']
        
        # è®¡ç®—é—´æ–­æ€§
        discontinuity_score = calculate_discontinuity(component_mask, w, h)
        
        # ä½ç½®è¯„åˆ†ï¼šè¶Šé è¿‘å›¾åƒä¸­å¿ƒï¼Œè¶Šå¯èƒ½æ˜¯ä¸­å¤®åˆ†éš”è™šçº¿
        image_center_x = lane_mask.shape[1] // 2
        center_distance = abs(x + w//2 - image_center_x) / image_center_x
        position_score = 1.0 - center_distance  # è¶Šé è¿‘ä¸­å¿ƒåˆ†æ•°è¶Šé«˜
        
        # ç»¼åˆåˆ¤æ–­æ˜¯å¦ä¸ºè™šçº¿
        is_dashed = False
        
        # ç­–ç•¥1: å¯†åº¦æä½çš„è‚¯å®šæ˜¯è™šçº¿
        if density < 0.06:
            is_dashed = True
            reason = "å¯†åº¦æä½"
        # ç­–ç•¥2: å¯†åº¦è¾ƒä½ä¸”é è¿‘ä¸­å¿ƒ
        elif density < 0.08 and position_score > 0.3:
            is_dashed = True  
            reason = "å¯†åº¦ä½+ä¸­å¿ƒä½ç½®"
        # ç­–ç•¥3: å¯†åº¦è¾ƒä½ä¸”é—´æ–­æ€§é«˜
        elif density < 0.10 and discontinuity_score > 0.2:
            is_dashed = True
            reason = "å¯†åº¦ä½+é«˜é—´æ–­æ€§"
        # ç­–ç•¥4: åœ¨å¤šç»„ä»¶æƒ…å†µä¸‹ï¼Œé€‰æ‹©å¯†åº¦æœ€ä½çš„ä¸€äº›ä½œä¸ºè™šçº¿
        elif total_components >= 3 and idx < total_components // 3:
            is_dashed = True
            reason = "ç›¸å¯¹æœ€ä½å¯†åº¦"
        # ç­–ç•¥5: å¦‚æœåªæœ‰1-2ä¸ªç»„ä»¶ï¼Œå¯†åº¦æœ€ä½çš„è®¾ä¸ºè™šçº¿
        elif total_components <= 2 and idx == 0 and density < 0.12:
            is_dashed = True
            reason = "å•ç‹¬ä½å¯†åº¦ç»„ä»¶"
        else:
            reason = "å¯†åº¦æ­£å¸¸"
        
        if is_dashed:  
            dashed_mask[component_mask == 1] = 1
            print(f"  è™šçº¿ç»„ä»¶ {i}: é¢ç§¯={area}, ä½ç½®=({x},{y}), å°ºå¯¸=({w}x{h}), å¯†åº¦={density:.3f}, åŸå› ={reason}")
        else:  
            solid_mask[component_mask == 1] = 1  
            print(f"  å®çº¿ç»„ä»¶ {i}: é¢ç§¯={area}, ä½ç½®=({x},{y}), å°ºå¯¸=({w}x{h}), å¯†åº¦={density:.3f}")
      
    print(f"âœ… å®çº¿åƒç´ æ€»æ•°: {np.sum(solid_mask)}")
    print(f"âœ… è™šçº¿åƒç´ æ€»æ•°: {np.sum(dashed_mask)}")
    
    return solid_mask, dashed_mask  
  
def is_dashed_line(component_mask, x, y, w, h):  
    """  
    åˆ¤æ–­æ˜¯å¦ä¸ºè™šçº¿  
    åŸºäºçº¿æ®µçš„é•¿å®½æ¯”ã€å¯†åº¦ã€é—´æ–­æ€§ç­‰ç‰¹å¾  
    """  
    # è®¡ç®—é•¿å®½æ¯”  
    aspect_ratio = max(w, h) / (min(w, h) + 1e-6)  
      
    # è®¡ç®—å¯†åº¦ï¼ˆåƒç´ æ•°é‡/è¾¹ç•Œæ¡†é¢ç§¯ï¼‰  
    density = np.sum(component_mask) / (w * h + 1e-6)  
    
    # è®¡ç®—ç»„ä»¶çš„å½¢çŠ¶ç‰¹å¾
    contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) > 0:
        contour = contours[0]
        # è®¡ç®—è½®å»“çš„å‡¸åŒ…é¢ç§¯æ¯”
        hull = cv2.convexHull(contour)
        contour_area = cv2.contourArea(contour)
        hull_area = cv2.contourArea(hull)
        solidity = contour_area / (hull_area + 1e-6)
        
        # è®¡ç®—çº¿æ®µçš„é—´æ–­æ€§ - æ£€æŸ¥å‚ç›´æ–¹å‘ä¸Šçš„è¿ç»­æ€§
        discontinuity_score = calculate_discontinuity(component_mask, w, h)
        
        # æ–°çš„è™šçº¿åˆ¤æ–­æ¡ä»¶ï¼ˆæ”¾å®½é˜ˆå€¼ï¼‰ï¼š
        # 1. ä½å¯†åº¦ + é•¿å®½æ¯”é€‚ä¸­
        # 2. æˆ–è€…ä¸­ç­‰å¯†åº¦ + é«˜é—´æ–­æ€§
        # 3. æˆ–è€…ä½å®ä½“åº¦ï¼ˆå½¢çŠ¶ä¸è§„åˆ™ï¼‰
        
        is_dashed = (density < 0.08) or \
                   (density < 0.12 and discontinuity_score > 0.3) or \
                   (density < 0.15 and solidity < 0.7) or \
                   (aspect_ratio > 4 and density < 0.1)
        
        print(f"    åˆ†æ: é•¿å®½æ¯”={aspect_ratio:.2f}, å¯†åº¦={density:.3f}, å®ä½“åº¦={solidity:.3f}, é—´æ–­æ€§={discontinuity_score:.3f} -> {'è™šçº¿' if is_dashed else 'å®çº¿'}")
        
        return is_dashed
    
    # é»˜è®¤æƒ…å†µï¼šå¦‚æœæ— æ³•åˆ†æè½®å»“ï¼Œä½¿ç”¨ç®€å•çš„å¯†åº¦åˆ¤æ–­
    return density < 0.1

def calculate_discontinuity(component_mask, w, h):
    """
    è®¡ç®—ç»„ä»¶çš„é—´æ–­æ€§åˆ†æ•°
    é€šè¿‡åˆ†æçº¿æ®µåœ¨å‚ç›´æ–¹å‘ä¸Šçš„è¿ç»­æ€§
    """
    if h < 10:  # å¤ªå°çš„ç»„ä»¶è·³è¿‡
        return 0
    
    # å°†ç»„ä»¶åˆ†æˆè‹¥å¹²æ°´å¹³å¸¦ï¼Œæ£€æŸ¥æ¯å¸¦çš„åƒç´ å¯†åº¦
    num_bands = min(10, h // 3)
    if num_bands < 3:
        return 0
    
    band_height = h // num_bands
    band_densities = []
    
    for i in range(num_bands):
        start_y = i * band_height
        end_y = min((i + 1) * band_height, h)
        band = component_mask[start_y:end_y, :]
        band_density = np.sum(band) / (band.shape[0] * band.shape[1] + 1e-6)
        band_densities.append(band_density)
    
    # è®¡ç®—å¯†åº¦å˜åŒ–çš„æ ‡å‡†å·®ï¼Œé«˜æ ‡å‡†å·®è¡¨ç¤ºé—´æ–­æ€§å¼º
    if len(band_densities) > 1:
        density_std = np.std(band_densities)
        density_mean = np.mean(band_densities)
        discontinuity = density_std / (density_mean + 1e-6)
        return min(float(discontinuity), 1.0)  # é™åˆ¶åœ¨[0,1]èŒƒå›´å†…
    
    return 0  
  
def show_seg_result_with_line_type(img, masks, lane_area_mask, confidence_mask, is_demo=True):  
    """  
    æ˜¾ç¤ºåˆ†å‰²ç»“æœï¼ŒåŒºåˆ†å®çº¿å’Œè™šçº¿  
    """  
    da_seg_mask, solid_mask, dashed_mask = masks  
    
    # åˆ›å»ºè¾“å‡ºå›¾åƒçš„å‰¯æœ¬
    img_result = img.copy()
    
    # 1. é¦–å…ˆæ˜¾ç¤ºå¯è¡Œé©¶åŒºåŸŸ - ç»¿è‰²åŠé€æ˜
    if da_seg_mask is not None and np.any(da_seg_mask):
        green_overlay = img_result.copy()
        green_overlay[da_seg_mask == 1] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
        img_result = cv2.addWeighted(img_result, 0.7, green_overlay, 0.3, 0)
    
    # 2. æ˜¾ç¤ºå®çº¿ - çº¢è‰²ï¼ˆBGRæ ¼å¼ï¼‰
    if solid_mask is not None and np.any(solid_mask):
        img_result[solid_mask > 0] = [0, 0, 255]  # BGR: çº¢è‰²
        print(f"ğŸ”´ æ£€æµ‹åˆ°å®çº¿åƒç´ æ•°: {np.sum(solid_mask > 0)}")
    
    # 3. æ˜¾ç¤ºè™šçº¿ - é»„è‰²ï¼ˆBGRæ ¼å¼ï¼‰  
    if dashed_mask is not None and np.any(dashed_mask):
        img_result[dashed_mask > 0] = [0, 255, 255]  # BGR: é»„è‰²
        print(f"ğŸŸ¡ æ£€æµ‹åˆ°è™šçº¿åƒç´ æ•°: {np.sum(dashed_mask > 0)}")
    
    return img_result  
  
def detect(cfg, opt):
    logger, _, _ = create_logger(
        cfg, cfg.LOG_DIR, 'demo')

    device = select_device(logger, opt.device)
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(opt.weights):
        print(f"âŒ é”™è¯¯: æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {opt.weights}")
        print("è¯·æ£€æŸ¥ä»¥ä¸‹äº‹é¡¹:")
        print("1. æƒé‡æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("2. æƒé‡æ–‡ä»¶æ˜¯å¦å·²ä¸‹è½½")
        print("3. å°è¯•ä½¿ç”¨ --weights å‚æ•°æŒ‡å®šæ­£ç¡®çš„æƒé‡æ–‡ä»¶è·¯å¾„")
        print("\nç¤ºä¾‹:")
        print("  python aa.py --source inference/images --weights /path/to/your/model.pth")
        return
    
    if os.path.exists(opt.save_dir):  # output dir
        shutil.rmtree(opt.save_dir)  # delete dir
    os.makedirs(opt.save_dir)  # make new dir
    half = device.type != 'cpu'  # half precision only supported on CUDA

    # Load model
    model = get_net(cfg)
    print(f"ğŸ”„ åŠ è½½æƒé‡æ–‡ä»¶: {opt.weights}")
    try:
        checkpoint = torch.load(opt.weights, map_location=device)
        model.load_state_dict(checkpoint['state_dict'])
        print("âœ… æƒé‡æ–‡ä»¶åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æƒé‡æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        return
        
    model = model.to(device)
    if half:
        model.half()  # to FP16    # Set Dataloader
    # æ£€æŸ¥è¾“å…¥æºæ˜¯å¦å­˜åœ¨
    if not opt.source.isnumeric() and not os.path.exists(opt.source):
        print(f"âŒ é”™è¯¯: è¾“å…¥æºä¸å­˜åœ¨: {opt.source}")
        print("è¯·æ£€æŸ¥ä»¥ä¸‹äº‹é¡¹:")
        print("1. è¾“å…¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("2. å¯¹äºå›¾ç‰‡: ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨ä¸”åŒ…å«å›¾ç‰‡æ–‡ä»¶")
        print("3. å¯¹äºè§†é¢‘: ç¡®ä¿è§†é¢‘æ–‡ä»¶å­˜åœ¨")
        print("4. å¯¹äºæ‘„åƒå¤´: ä½¿ç”¨æ•°å­— (å¦‚: --source 0)")
        return
        
    if opt.source.isnumeric():
        cudnn.benchmark = True  # set True to speed up constant image size inference
        dataset = LoadStreams(opt.source, img_size=opt.img_size)
        print(f"ğŸ¥ ä½¿ç”¨æ‘„åƒå¤´: {opt.source}")
        # batch_size = len(dataset) (ä¸éœ€è¦å­˜å‚¨å˜é‡)
    else:
        dataset = LoadImages(opt.source, img_size=opt.img_size)
        print(f"ğŸ“ å¤„ç†è¾“å…¥: {opt.source}")
        # batch_size = 1 (ä¸éœ€è¦å­˜å‚¨å˜é‡)
  
    # Get names and colors  
    names = model.module.names if hasattr(model, 'module') else model.names  
    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]  
  
    # Run inference  
    t0 = time.time()  
  
    vid_path, vid_writer = None, None  
    img = torch.zeros((1, 3, opt.img_size, opt.img_size), device=device)  # init img  
    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once  
    model.eval()  
  
    inf_time = AverageMeter()  
    nms_time = AverageMeter()  
      
    for i, (path, img, img_det, vid_cap, shapes) in tqdm(enumerate(dataset), total=len(dataset)):  
        img = transform(img).to(device)  
        img = img.half() if half else img.float()  # uint8 to fp16/32  
        if img.ndimension() == 3:  
            img = img.unsqueeze(0)  
          
        # Inference  
        t1 = time_synchronized()  
        det_out, da_seg_out, ll_seg_out = model(img)  
        t2 = time_synchronized()  
          
        inf_out, _ = det_out  
        inf_time.update(t2-t1, img.size(0))  
  
        # Apply NMS  
        t3 = time_synchronized()  
        det_pred = non_max_suppression(inf_out, conf_thres=opt.conf_thres, iou_thres=opt.iou_thres, classes=None, agnostic=False)  
        t4 = time_synchronized()  
  
        nms_time.update(t4-t3, img.size(0))  
        det = det_pred[0]  
  
        save_path = str(opt.save_dir +'/'+ Path(path).name) if dataset.mode != 'stream' else str(opt.save_dir + '/' + "web.mp4")  
  
        _, _, height, width = img.shape  
        h, w, _ = img_det.shape  
        pad_w, pad_h = shapes[1][1]  
        pad_w = int(pad_w)  
        pad_h = int(pad_h)  
        ratio = shapes[1][0][1]  
  
        # å¤„ç†å¯è¡Œé©¶åŒºåŸŸåˆ†å‰²  
        da_predict = da_seg_out[:, :, pad_h:(height-pad_h), pad_w:(width-pad_w)]  
        da_seg_mask = torch.nn.functional.interpolate(da_predict, scale_factor=int(1/ratio), mode='bilinear')  
        _, da_seg_mask = torch.max(da_seg_mask, 1)  
        da_seg_mask = da_seg_mask.int().squeeze().cpu().numpy()  
  
        # å¤„ç†è½¦é“çº¿åˆ†å‰²  
        ll_predict = ll_seg_out[:, :, pad_h:(height-pad_h), pad_w:(width-pad_w)]  
        ll_seg_mask = torch.nn.functional.interpolate(ll_predict, scale_factor=int(1/ratio), mode='bilinear')  
        _, ll_seg_mask = torch.max(ll_seg_mask, 1)  
        ll_seg_mask = ll_seg_mask.int().squeeze().cpu().numpy()  
          
        # å¯ç”¨å½¢æ€å­¦å¤„ç†æ¥æ”¹å–„çº¿å‹æ£€æµ‹æ•ˆæœ  
        ll_seg_mask = morphological_process(ll_seg_mask, kernel_size=7, func_type=cv2.MORPH_OPEN)  
        ll_seg_mask = connect_lane(ll_seg_mask)  
  
        print(f"ğŸ“ å¤„ç†ç¬¬ {i+1} å¸§ï¼Œè½¦é“çº¿åƒç´ æ€»æ•°: {np.sum(ll_seg_mask)}")
        
        # æ–°å¢ï¼šåˆ†æçº¿å‹  
        solid_mask, dashed_mask = analyze_lane_type(ll_seg_mask)  
  
        # ä½¿ç”¨æ–°çš„å¯è§†åŒ–å‡½æ•°  
        img_det = show_seg_result_with_line_type(img_det, (da_seg_mask, solid_mask, dashed_mask), None, None, is_demo=True)  
  
        # ç»˜åˆ¶æ£€æµ‹æ¡†  
        if len(det):  
            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img_det.shape).round()  
            for *xyxy, conf, cls in reversed(det):  
                label_det_pred = f'{names[int(cls)]} {conf:.2f}'  
                plot_one_box(xyxy, img_det, label=label_det_pred, color=colors[int(cls)], line_thickness=2)  
          
        # æ·»åŠ å›¾ä¾‹ - ä½¿ç”¨ç™½è‰²æ–‡å­—ï¼Œé»‘è‰²æè¾¹ä»¥æé«˜å¯è§æ€§
        cv2.putText(img_det, 'Red: Solid Line', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)  # çº¢è‰²æ–‡å­—
        cv2.putText(img_det, 'Red: Solid Line', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)  # ç™½è‰²æè¾¹
        
        cv2.putText(img_det, 'Yellow: Dashed Line', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)  # é»„è‰²æ–‡å­—  
        cv2.putText(img_det, 'Yellow: Dashed Line', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)  # ç™½è‰²æè¾¹
        
        cv2.putText(img_det, 'Green: Drivable Area', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)  # ç»¿è‰²æ–‡å­—
        cv2.putText(img_det, 'Green: Drivable Area', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)  # ç™½è‰²æè¾¹  
          
        if dataset.mode == 'images':  
            cv2.imwrite(save_path, img_det)  
  
        elif dataset.mode == 'video':  
            if vid_path != save_path:  # new video  
                vid_path = save_path  
                if isinstance(vid_writer, cv2.VideoWriter):  
                    vid_writer.release()  # release previous video writer  
  
                fps = vid_cap.get(cv2.CAP_PROP_FPS)  
                h, w, _ = img_det.shape  
                # ä¿®å¤ VideoWriter å…¼å®¹æ€§é—®é¢˜ - ä½¿ç”¨ç›´æ¥çš„fourccç¼–ç 
                fourcc_code = cv2.VideoWriter.fourcc('m', 'p', '4', 'v')
                vid_writer = cv2.VideoWriter(save_path, fourcc_code, fps, (w, h))  
            if vid_writer is not None:
                vid_writer.write(img_det)  
          
        else:  
            cv2.imshow('YOLOP - Lane Detection', img_det)  
            if cv2.waitKey(1) == ord('q'):  # æŒ‰qé”®é€€å‡º  
                break  
  
    print('Results saved to %s' % Path(opt.save_dir))  
    print('Done. (%.3fs)' % (time.time() - t0))  
    print('inf : (%.4fs/frame)   nms : (%.4fs/frame)' % (inf_time.avg, nms_time.avg))  
  
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='YOLOPè½¦é“çº¿æ£€æµ‹ - æ”¯æŒå®çº¿è™šçº¿åŒºåˆ†æ˜¾ç¤º')
    parser.add_argument('--weights', nargs='+', type=str, 
                       default='weights/End-to-end.pth', 
                       help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ (å¦‚: weights/model.pth)')
    parser.add_argument('--source', type=str, 
                       default='inference/images', 
                       help='è¾“å…¥æº: å›¾ç‰‡æ–‡ä»¶å¤¹/è§†é¢‘æ–‡ä»¶/æ‘„åƒå¤´ç¼–å·(0,1,2...)')
    parser.add_argument('--img-size', type=int, default=640, 
                       help='æ¨ç†å›¾åƒå°ºå¯¸ (åƒç´ )')
    parser.add_argument('--conf-thres', type=float, default=0.25, 
                       help='ç›®æ ‡æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--iou-thres', type=float, default=0.45, 
                       help='NMSçš„IOUé˜ˆå€¼')
    parser.add_argument('--device', default='cpu', 
                       help='è®¡ç®—è®¾å¤‡: cpu æˆ– cudaè®¾å¤‡ç¼–å· (å¦‚: 0 æˆ– 0,1,2,3)')
    parser.add_argument('--save-dir', type=str, default='inference/output', 
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--augment', action='store_true', 
                       help='å¯ç”¨å¢å¼ºæ¨ç†')
    parser.add_argument('--update', action='store_true', 
                       help='æ›´æ–°æ‰€æœ‰æ¨¡å‹')
    
    opt = parser.parse_args()
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("ğŸš€ YOLOPè½¦é“çº¿æ£€æµ‹å¯åŠ¨")
    print("=" * 50)
    print(f"æƒé‡æ–‡ä»¶: {opt.weights}")
    print(f"è¾“å…¥æº:   {opt.source}")
    print(f"è¾“å‡ºç›®å½•: {opt.save_dir}")
    print(f"è®¡ç®—è®¾å¤‡: {opt.device}")
    print(f"å›¾åƒå°ºå¯¸: {opt.img_size}")
    print("=" * 50)
    print("åŠŸèƒ½ç‰¹è‰²:")
    print("âœ… å®çº¿æ˜¾ç¤º: çº¢è‰²")
    print("âœ… è™šçº¿æ˜¾ç¤º: é»„è‰²") 
    print("âœ… å¯è¡Œé©¶åŒºåŸŸ: ç»¿è‰²")
    print("âœ… å®æ—¶æŒ‰ 'q' é”®é€€å‡º")
    print("=" * 50)
    
    with torch.no_grad():
        detect(cfg, opt)